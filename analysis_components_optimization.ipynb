{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce130f32",
   "metadata": {},
   "source": [
    "# üîç An√°lise Completa dos Componentes do Quiz Quest Challenge Verse\n",
    "\n",
    "**Objetivo:** Analisar complexidade, identificar componentes com JSON/JavaScript complexos e propor otimiza√ß√µes para `/editor-fixed`.\n",
    "\n",
    "## üìä Escopo da An√°lise\n",
    "- **Target:** Componentes em `src/components/editor/`\n",
    "- **M√©tricas:** Complexidade JSON, depend√™ncias, linhas de c√≥digo, padr√µes de uso\n",
    "- **Output:** Plano de limpeza e otimiza√ß√£o para editor-fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19660e0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Bibliotecas Necess√°rias\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Diret√≥rio base do projeto\n",
    "BASE_DIR = \"/workspaces/quiz-quest-challenge-verse\"\n",
    "COMPONENTS_DIR = f\"{BASE_DIR}/src/components/editor\"\n",
    "TEMPLATES_DIR = f\"{BASE_DIR}/templates\"\n",
    "\n",
    "print(f\"üìÇ Analisando componentes em: {COMPONENTS_DIR}\")\n",
    "print(f\"üìÑ Analisando templates em: {TEMPLATES_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063bd286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e Analisar Dados JSON\n",
    "def load_json_templates():\n",
    "    \"\"\"Carrega todos os templates JSON das 21 etapas\"\"\"\n",
    "    templates = {}\n",
    "    \n",
    "    # Buscar arquivos step-XX-template.json\n",
    "    json_files = glob.glob(f\"{TEMPLATES_DIR}/step-*-template.json\")\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                filename = os.path.basename(file_path)\n",
    "                templates[filename] = data\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao carregar {file_path}: {e}\")\n",
    "    \n",
    "    return templates\n",
    "\n",
    "def analyze_json_complexity(templates):\n",
    "    \"\"\"Analisa complexidade dos templates JSON\"\"\"\n",
    "    analysis = []\n",
    "    \n",
    "    for filename, template in templates.items():\n",
    "        # M√©tricas de complexidade JSON\n",
    "        json_str = json.dumps(template)\n",
    "        \n",
    "        metrics = {\n",
    "            'filename': filename,\n",
    "            'step_number': template.get('stepNumber', 0),\n",
    "            'step_name': template.get('name', ''),\n",
    "            'step_type': template.get('type', ''),\n",
    "            'json_size': len(json_str),\n",
    "            'blocks_count': len(template.get('blocks', [])),\n",
    "            'properties_count': sum(len(block.get('properties', {})) for block in template.get('blocks', [])),\n",
    "            'nesting_level': max_nesting_level(template),\n",
    "            'unique_block_types': len(set(block.get('type') for block in template.get('blocks', []))),\n",
    "        }\n",
    "        \n",
    "        # Complexidade baseada em propriedades espec√≠ficas\n",
    "        complex_props = 0\n",
    "        for block in template.get('blocks', []):\n",
    "            props = block.get('properties', {})\n",
    "            # Contar propriedades complexas (objetos, arrays)\n",
    "            complex_props += sum(1 for v in props.values() \n",
    "                               if isinstance(v, (dict, list)))\n",
    "        \n",
    "        metrics['complex_properties'] = complex_props\n",
    "        metrics['complexity_score'] = (\n",
    "            metrics['json_size'] * 0.001 + \n",
    "            metrics['blocks_count'] * 2 + \n",
    "            metrics['properties_count'] * 1.5 + \n",
    "            metrics['nesting_level'] * 3 + \n",
    "            metrics['complex_properties'] * 4\n",
    "        )\n",
    "        \n",
    "        analysis.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(analysis)\n",
    "\n",
    "def max_nesting_level(obj, current_level=0):\n",
    "    \"\"\"Calcula n√≠vel m√°ximo de aninhamento em JSON\"\"\"\n",
    "    if not isinstance(obj, (dict, list)):\n",
    "        return current_level\n",
    "    \n",
    "    max_level = current_level\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for value in obj.values():\n",
    "            level = max_nesting_level(value, current_level + 1)\n",
    "            max_level = max(max_level, level)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            level = max_nesting_level(item, current_level + 1)\n",
    "            max_level = max(max_level, level)\n",
    "    \n",
    "    return max_level\n",
    "\n",
    "# Executar an√°lise dos templates JSON\n",
    "templates = load_json_templates()\n",
    "json_df = analyze_json_complexity(templates)\n",
    "\n",
    "print(f\"üìä Carregados {len(templates)} templates JSON\")\n",
    "print(f\"üéØ Template mais complexo: {json_df.loc[json_df['complexity_score'].idxmax(), 'filename']}\")\n",
    "json_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a93b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar Componentes JavaScript\n",
    "def analyze_tsx_components():\n",
    "    \"\"\"Analisa componentes TypeScript/React\"\"\"\n",
    "    components_analysis = []\n",
    "    \n",
    "    # Buscar todos os arquivos .tsx em components/editor\n",
    "    tsx_files = []\n",
    "    for root, dirs, files in os.walk(COMPONENTS_DIR):\n",
    "        for file in files:\n",
    "            if file.endswith('.tsx'):\n",
    "                tsx_files.append(os.path.join(root, file))\n",
    "    \n",
    "    for file_path in tsx_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # An√°lise de m√©tricas do c√≥digo\n",
    "            lines = content.split('\\n')\n",
    "            non_empty_lines = [line for line in lines if line.strip()]\n",
    "            \n",
    "            metrics = {\n",
    "                'filepath': file_path,\n",
    "                'filename': os.path.basename(file_path),\n",
    "                'directory': os.path.dirname(file_path).replace(COMPONENTS_DIR, ''),\n",
    "                'total_lines': len(lines),\n",
    "                'code_lines': len(non_empty_lines),\n",
    "                'imports_count': len(re.findall(r'^import\\s+', content, re.MULTILINE)),\n",
    "                'functions_count': len(re.findall(r'(function\\s+\\w+|const\\s+\\w+\\s*=\\s*\\(.*?\\)\\s*=>|\\w+:\\s*\\(.*?\\)\\s*=>', content)),\n",
    "                'interfaces_count': len(re.findall(r'interface\\s+\\w+', content)),\n",
    "                'usestate_count': len(re.findall(r'useState', content)),\n",
    "                'useeffect_count': len(re.findall(r'useEffect', content)),\n",
    "                'json_operations': len(re.findall(r'JSON\\.(parse|stringify)', content)),\n",
    "                'properties_usage': len(re.findall(r'\\.properties\\??\\[|properties\\??\\.|block\\.properties', content)),\n",
    "                'complex_jsx': len(re.findall(r'\\{[^}]*\\?[^}]*:[^}]*\\}', content)),\n",
    "                'typescript_annotations': len(re.findall(r':\\s*[A-Z]\\w*', content)),\n",
    "            }\n",
    "            \n",
    "            # Calcular score de complexidade JavaScript/TypeScript\n",
    "            metrics['js_complexity_score'] = (\n",
    "                metrics['code_lines'] * 0.1 +\n",
    "                metrics['functions_count'] * 2 +\n",
    "                metrics['interfaces_count'] * 1.5 +\n",
    "                metrics['usestate_count'] * 3 +\n",
    "                metrics['useeffect_count'] * 3 +\n",
    "                metrics['json_operations'] * 5 +\n",
    "                metrics['properties_usage'] * 2 +\n",
    "                metrics['complex_jsx'] * 1.5\n",
    "            )\n",
    "            \n",
    "            # Identificar padr√µes problem√°ticos\n",
    "            issues = []\n",
    "            if metrics['json_operations'] > 10:\n",
    "                issues.append('JSON_HEAVY')\n",
    "            if metrics['properties_usage'] > 20:\n",
    "                issues.append('PROPERTY_HEAVY')\n",
    "            if metrics['code_lines'] > 500:\n",
    "                issues.append('TOO_LONG')\n",
    "            if metrics['usestate_count'] > 10:\n",
    "                issues.append('STATE_HEAVY')\n",
    "            \n",
    "            metrics['issues'] = ','.join(issues)\n",
    "            \n",
    "            components_analysis.append(metrics)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao analisar {file_path}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(components_analysis)\n",
    "\n",
    "# Executar an√°lise dos componentes TSX\n",
    "components_df = analyze_tsx_components()\n",
    "\n",
    "print(f\"üîß Analisados {len(components_df)} componentes TSX\")\n",
    "print(f\"‚ö†Ô∏è  Componentes com problemas: {len(components_df[components_df['issues'] != ''])}\")\n",
    "components_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular M√©tricas de Complexidade\n",
    "def calculate_comprehensive_complexity():\n",
    "    \"\"\"Calcula m√©tricas abrangentes de complexidade\"\"\"\n",
    "    \n",
    "    # An√°lise por diret√≥rio\n",
    "    directory_stats = components_df.groupby('directory').agg({\n",
    "        'filename': 'count',\n",
    "        'code_lines': ['sum', 'mean'],\n",
    "        'js_complexity_score': ['sum', 'mean'],\n",
    "        'properties_usage': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Top 10 componentes mais complexos\n",
    "    most_complex = components_df.nlargest(10, 'js_complexity_score')[[\n",
    "        'filename', 'directory', 'js_complexity_score', 'code_lines', \n",
    "        'properties_usage', 'json_operations', 'issues'\n",
    "    ]]\n",
    "    \n",
    "    # An√°lise de problemas\n",
    "    issue_analysis = {}\n",
    "    all_issues = []\n",
    "    for issues_str in components_df['issues']:\n",
    "        if issues_str:\n",
    "            all_issues.extend(issues_str.split(','))\n",
    "    \n",
    "    issue_counts = Counter(all_issues)\n",
    "    \n",
    "    # Componentes que mais usam JSON\n",
    "    json_heavy = components_df[components_df['json_operations'] > 0].nlargest(10, 'json_operations')[[\n",
    "        'filename', 'directory', 'json_operations', 'properties_usage', 'js_complexity_score'\n",
    "    ]]\n",
    "    \n",
    "    return {\n",
    "        'directory_stats': directory_stats,\n",
    "        'most_complex': most_complex,\n",
    "        'issue_counts': issue_counts,\n",
    "        'json_heavy': json_heavy\n",
    "    }\n",
    "\n",
    "# Executar an√°lise de complexidade\n",
    "complexity_analysis = calculate_comprehensive_complexity()\n",
    "\n",
    "print(\"üìä AN√ÅLISE DE COMPLEXIDADE COMPLETA\")\n",
    "print(\"\\nüèóÔ∏è  ESTAT√çSTICAS POR DIRET√ìRIO:\")\n",
    "print(complexity_analysis['directory_stats'])\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  PROBLEMAS IDENTIFICADOS:\")\n",
    "for issue, count in complexity_analysis['issue_counts'].items():\n",
    "    print(f\"  - {issue}: {count} componentes\")\n",
    "\n",
    "print(\"\\nüîù TOP 5 COMPONENTES MAIS COMPLEXOS:\")\n",
    "print(complexity_analysis['most_complex'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar Componentes Mais Complexos\n",
    "def create_complexity_visualizations():\n",
    "    \"\"\"Cria visualiza√ß√µes da an√°lise de complexidade\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Distribui√ß√£o de complexidade por diret√≥rio\n",
    "    components_df.boxplot(column='js_complexity_score', by='directory', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Complexidade por Diret√≥rio')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Top 10 componentes mais complexos\n",
    "    top_complex = complexity_analysis['most_complex'].head(10)\n",
    "    axes[0,1].barh(top_complex['filename'], top_complex['js_complexity_score'])\n",
    "    axes[0,1].set_title('Top 10 Componentes Mais Complexos')\n",
    "    axes[0,1].set_xlabel('Score de Complexidade')\n",
    "    \n",
    "    # 3. Correla√ß√£o: Linhas de c√≥digo vs Complexidade\n",
    "    axes[1,0].scatter(components_df['code_lines'], components_df['js_complexity_score'], alpha=0.6)\n",
    "    axes[1,0].set_xlabel('Linhas de C√≥digo')\n",
    "    axes[1,0].set_ylabel('Score de Complexidade')\n",
    "    axes[1,0].set_title('Correla√ß√£o: C√≥digo vs Complexidade')\n",
    "    \n",
    "    # 4. Uso de JSON vs Propriedades\n",
    "    axes[1,1].scatter(components_df['json_operations'], components_df['properties_usage'], alpha=0.6)\n",
    "    axes[1,1].set_xlabel('Opera√ß√µes JSON')\n",
    "    axes[1,1].set_ylabel('Uso de Properties')\n",
    "    axes[1,1].set_title('JSON vs Properties Usage')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('üîç AN√ÅLISE DE COMPLEXIDADE DOS COMPONENTES', y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    # Heatmap de problemas por componente\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Criar matriz de problemas\n",
    "    problem_components = components_df[components_df['issues'] != ''].copy()\n",
    "    if len(problem_components) > 0:\n",
    "        problem_matrix = pd.DataFrame()\n",
    "        \n",
    "        issue_types = ['JSON_HEAVY', 'PROPERTY_HEAVY', 'TOO_LONG', 'STATE_HEAVY']\n",
    "        \n",
    "        for issue_type in issue_types:\n",
    "            problem_matrix[issue_type] = problem_components['issues'].str.contains(issue_type, na=False).astype(int)\n",
    "        \n",
    "        problem_matrix.index = problem_components['filename']\n",
    "        \n",
    "        sns.heatmap(problem_matrix, annot=True, cmap='Reds', ax=ax, cbar_kws={'label': 'Presen√ßa do Problema'})\n",
    "        ax.set_title('üö® Mapa de Problemas por Componente')\n",
    "        ax.set_xlabel('Tipos de Problemas')\n",
    "        ax.set_ylabel('Componentes')\n",
    "        \n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "create_complexity_visualizations()\n",
    "\n",
    "# An√°lise espec√≠fica do JSON\n",
    "print(\"\\nüìÑ AN√ÅLISE DOS TEMPLATES JSON:\")\n",
    "print(f\"Template mais complexo: {json_df.loc[json_df['complexity_score'].idxmax(), 'step_name']}\")\n",
    "print(f\"M√©dia de blocos por template: {json_df['blocks_count'].mean():.1f}\")\n",
    "print(f\"Template com mais propriedades: {json_df.loc[json_df['properties_count'].idxmax(), 'step_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a908e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar Limpeza de Dados\n",
    "def identify_cleanup_opportunities():\n",
    "    \"\"\"Identifica oportunidades de limpeza e otimiza√ß√£o\"\"\"\n",
    "    \n",
    "    cleanup_report = {\n",
    "        'duplicated_components': [],\n",
    "        'oversized_components': [],\n",
    "        'json_optimization_candidates': [],\n",
    "        'refactoring_priorities': [],\n",
    "        'unused_dependencies': []\n",
    "    }\n",
    "    \n",
    "    # 1. Componentes duplicados (nomes similares)\n",
    "    filenames = components_df['filename'].tolist()\n",
    "    for i, name1 in enumerate(filenames):\n",
    "        for name2 in filenames[i+1:]:\n",
    "            # Verificar similaridade de nomes (sem extens√£o)\n",
    "            base1 = name1.replace('.tsx', '').replace('.backup', '').lower()\n",
    "            base2 = name2.replace('.tsx', '').replace('.backup', '').lower()\n",
    "            \n",
    "            if base1 == base2 and name1 != name2:\n",
    "                cleanup_report['duplicated_components'].append((name1, name2))\n",
    "    \n",
    "    # 2. Componentes muito grandes (candidatos para refatora√ß√£o)\n",
    "    oversized = components_df[components_df['code_lines'] > 300][['filename', 'code_lines', 'js_complexity_score']]\n",
    "    cleanup_report['oversized_components'] = oversized.to_dict('records')\n",
    "    \n",
    "    # 3. Componentes com muito uso de JSON (candidatos para otimiza√ß√£o)\n",
    "    json_candidates = components_df[components_df['json_operations'] > 5][[\n",
    "        'filename', 'json_operations', 'properties_usage', 'js_complexity_score'\n",
    "    ]]\n",
    "    cleanup_report['json_optimization_candidates'] = json_candidates.to_dict('records')\n",
    "    \n",
    "    # 4. Prioridades de refatora√ß√£o (baseado em complexidade e problemas)\n",
    "    priority_score = (\n",
    "        components_df['js_complexity_score'] * 0.4 +\n",
    "        components_df['code_lines'] * 0.01 +\n",
    "        components_df['json_operations'] * 5 +\n",
    "        components_df['properties_usage'] * 0.5\n",
    "    )\n",
    "    \n",
    "    components_df['refactor_priority'] = priority_score\n",
    "    top_priorities = components_df.nlargest(10, 'refactor_priority')[[\n",
    "        'filename', 'directory', 'refactor_priority', 'issues'\n",
    "    ]]\n",
    "    cleanup_report['refactoring_priorities'] = top_priorities.to_dict('records')\n",
    "    \n",
    "    return cleanup_report\n",
    "\n",
    "def generate_cleanup_plan():\n",
    "    \"\"\"Gera plano de limpeza espec√≠fico\"\"\"\n",
    "    \n",
    "    plan = {\n",
    "        'immediate_actions': [],\n",
    "        'short_term': [],\n",
    "        'long_term': [],\n",
    "        'automated_fixes': []\n",
    "    }\n",
    "    \n",
    "    # A√ß√µes imediatas\n",
    "    plan['immediate_actions'] = [\n",
    "        \"Remover arquivos .backup duplicados\",\n",
    "        \"Consolidar componentes com nomes similares\",\n",
    "        \"Aplicar Prettier em todos os arquivos\",\n",
    "        \"Remover imports n√£o utilizados\"\n",
    "    ]\n",
    "    \n",
    "    # Curto prazo\n",
    "    plan['short_term'] = [\n",
    "        \"Refatorar componentes com >300 linhas\",\n",
    "        \"Otimizar componentes com muitas opera√ß√µes JSON\",\n",
    "        \"Extrair l√≥gica comum em hooks customizados\",\n",
    "        \"Padronizar interface de propriedades\"\n",
    "    ]\n",
    "    \n",
    "    # Longo prazo\n",
    "    plan['long_term'] = [\n",
    "        \"Implementar sistema de cache para templates JSON\",\n",
    "        \"Migrar para arquitetura de componentes compostos\",\n",
    "        \"Implementar lazy loading inteligente\",\n",
    "        \"Criar sistema de valida√ß√£o autom√°tica\"\n",
    "    ]\n",
    "    \n",
    "    # Corre√ß√µes automatiz√°veis\n",
    "    plan['automated_fixes'] = [\n",
    "        \"Remover console.log() em produ√ß√£o\",\n",
    "        \"Padronizar nomes de propriedades\",\n",
    "        \"Aplicar regras de linting automaticamente\",\n",
    "        \"Gerar documenta√ß√£o autom√°tica\"\n",
    "    ]\n",
    "    \n",
    "    return plan\n",
    "\n",
    "# Executar an√°lise de limpeza\n",
    "cleanup_report = identify_cleanup_opportunities()\n",
    "cleanup_plan = generate_cleanup_plan()\n",
    "\n",
    "print(\"üßπ RELAT√ìRIO DE LIMPEZA\")\n",
    "print(f\"\\nüìä Componentes duplicados encontrados: {len(cleanup_report['duplicated_components'])}\")\n",
    "print(f\"üìè Componentes muito grandes: {len(cleanup_report['oversized_components'])}\")\n",
    "print(f\"üîß Candidatos para otimiza√ß√£o JSON: {len(cleanup_report['json_optimization_candidates'])}\")\n",
    "\n",
    "print(\"\\nüéØ TOP 5 PRIORIDADES DE REFATORA√á√ÉO:\")\n",
    "for i, priority in enumerate(cleanup_report['refactoring_priorities'][:5], 1):\n",
    "    print(f\"{i}. {priority['filename']} (Score: {priority['refactor_priority']:.1f})\")\n",
    "    if priority['issues']:\n",
    "        print(f\"   Problemas: {priority['issues']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar Relat√≥rio de An√°lise\n",
    "def create_comprehensive_report():\n",
    "    \"\"\"Cria relat√≥rio completo da an√°lise\"\"\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "# üìä RELAT√ìRIO COMPLETO DE AN√ÅLISE DOS COMPONENTES\n",
    "## Quiz Quest Challenge Verse - An√°lise de Complexidade\n",
    "\n",
    "### üìà ESTAT√çSTICAS GERAIS\n",
    "- **Total de componentes TSX analisados**: {len(components_df)}\n",
    "- **Total de templates JSON**: {len(json_df)}\n",
    "- **Linhas de c√≥digo total**: {components_df['code_lines'].sum():,}\n",
    "- **Componentes com problemas**: {len(components_df[components_df['issues'] != ''])}\n",
    "\n",
    "### üèÜ COMPONENTES MAIS COMPLEXOS\n",
    "1. **{complexity_analysis['most_complex'].iloc[0]['filename']}** \n",
    "   - Complexidade: {complexity_analysis['most_complex'].iloc[0]['js_complexity_score']:.1f}\n",
    "   - Linhas: {complexity_analysis['most_complex'].iloc[0]['code_lines']}\n",
    "   - Problemas: {complexity_analysis['most_complex'].iloc[0]['issues']}\n",
    "\n",
    "2. **{complexity_analysis['most_complex'].iloc[1]['filename']}**\n",
    "   - Complexidade: {complexity_analysis['most_complex'].iloc[1]['js_complexity_score']:.1f}\n",
    "   - Linhas: {complexity_analysis['most_complex'].iloc[1]['code_lines']}\n",
    "   - Problemas: {complexity_analysis['most_complex'].iloc[1]['issues']}\n",
    "\n",
    "### üö® PRINCIPAIS PROBLEMAS IDENTIFICADOS\n",
    "\"\"\"\n",
    "    \n",
    "    for issue, count in complexity_analysis['issue_counts'].items():\n",
    "        report += f\"- **{issue}**: {count} componentes\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "\n",
    "### üìÑ AN√ÅLISE DOS TEMPLATES JSON\n",
    "- **Template mais complexo**: {json_df.loc[json_df['complexity_score'].idxmax(), 'step_name']}\n",
    "- **M√©dia de blocos por template**: {json_df['blocks_count'].mean():.1f}\n",
    "- **Template com mais propriedades**: {json_df.loc[json_df['properties_count'].idxmax(), 'step_name']} ({json_df['properties_count'].max()} propriedades)\n",
    "\n",
    "### üéØ RECOMENDA√á√ïES PRIORIT√ÅRIAS\n",
    "1. **Refatorar componentes grandes** (>300 linhas)\n",
    "2. **Otimizar uso excessivo de JSON**\n",
    "3. **Consolidar componentes duplicados**\n",
    "4. **Extrair l√≥gica comum em hooks**\n",
    "5. **Implementar lazy loading inteligente**\n",
    "\n",
    "### üìä M√âTRICAS DE QUALIDADE\n",
    "- **Complexidade m√©dia**: {components_df['js_complexity_score'].mean():.1f}\n",
    "- **Linhas m√©dias por componente**: {components_df['code_lines'].mean():.1f}\n",
    "- **Componentes com >10 opera√ß√µes JSON**: {len(components_df[components_df['json_operations'] > 10])}\n",
    "- **Taxa de problemas**: {len(components_df[components_df['issues'] != '']) / len(components_df) * 100:.1f}%\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Gerar e salvar relat√≥rio\n",
    "comprehensive_report = create_comprehensive_report()\n",
    "print(comprehensive_report)\n",
    "\n",
    "# Salvar relat√≥rio em arquivo\n",
    "report_path = f\"{BASE_DIR}/COMPONENT_ANALYSIS_REPORT.md\"\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(comprehensive_report)\n",
    "\n",
    "print(f\"\\nüíæ Relat√≥rio salvo em: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar Ideias para Editor-Fixed\n",
    "def generate_editor_fixed_optimizations():\n",
    "    \"\"\"Gera sugest√µes espec√≠ficas para otimiza√ß√£o do /editor-fixed\"\"\"\n",
    "    \n",
    "    optimizations = {\n",
    "        'architecture_improvements': {\n",
    "            'component_splitting': {\n",
    "                'description': 'Dividir editor-fixed em componentes menores e especializados',\n",
    "                'benefits': ['Melhor manutenibilidade', 'Lazy loading', 'Menor bundle size'],\n",
    "                'implementation': [\n",
    "                    'Extrair ToolbarSection como componente separado',\n",
    "                    'Separar PropertiesPanel em sub-pain√©is especializados',\n",
    "                    'Criar ComponentsLibrary como m√≥dulo independente',\n",
    "                    'Isolar CanvasArea com seus pr√≥prios hooks'\n",
    "                ]\n",
    "            },\n",
    "            'state_management': {\n",
    "                'description': 'Otimizar gerenciamento de estado com padr√µes mais eficientes',\n",
    "                'benefits': ['Melhor performance', 'Estado mais previs√≠vel', 'Debugging mais f√°cil'],\n",
    "                'implementation': [\n",
    "                    'Implementar useReducer para estado complexo',\n",
    "                    'Memoiza√ß√£o inteligente com useMemo/useCallback',\n",
    "                    'Context API para estado global do editor',\n",
    "                    'State normalization para templates JSON'\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'json_optimizations': {\n",
    "            'template_caching': {\n",
    "                'description': 'Sistema de cache inteligente para templates JSON',\n",
    "                'benefits': ['Carregamento mais r√°pido', 'Menor uso de mem√≥ria', 'Offline support'],\n",
    "                'implementation': [\n",
    "                    'Cache em localStorage para templates frequentes',\n",
    "                    'Lazy loading de templates por demanda',\n",
    "                    'Compress√£o JSON com gzip virtual',\n",
    "                    'Invalida√ß√£o autom√°tica baseada em hash'\n",
    "                ]\n",
    "            },\n",
    "            'schema_validation': {\n",
    "                'description': 'Valida√ß√£o autom√°tica de schemas JSON',\n",
    "                'benefits': ['Menos erros runtime', 'Melhor UX', 'Debug mais f√°cil'],\n",
    "                'implementation': [\n",
    "                    'JSON Schema para templates das 21 etapas',\n",
    "                    'Valida√ß√£o em tempo real no editor',\n",
    "                    'Auto-complete baseado em schema',\n",
    "                    'Migra√ß√£o autom√°tica de vers√µes'\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'performance_enhancements': {\n",
    "            'virtual_scrolling': {\n",
    "                'description': 'Implementar virtual scrolling para listas grandes',\n",
    "                'benefits': ['Performance com muitos componentes', 'Menor uso de DOM'],\n",
    "                'implementation': [\n",
    "                    'React-window para lista de componentes',\n",
    "                    'Intersection Observer para lazy loading',\n",
    "                    'Batch updates para m√∫ltiplas mudan√ßas'\n",
    "                ]\n",
    "            },\n",
    "            'code_splitting': {\n",
    "                'description': 'Divis√£o inteligente de c√≥digo por funcionalidade',\n",
    "                'benefits': ['Carregamento inicial mais r√°pido', 'Bundle splitting'],\n",
    "                'implementation': [\n",
    "                    'Lazy loading por categoria de componente',\n",
    "                    'Dynamic imports para pain√©is especializados',\n",
    "                    'Preload de componentes frequentemente usados'\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'developer_experience': {\n",
    "            'debugging_tools': {\n",
    "                'description': 'Ferramentas avan√ßadas de debug para desenvolvimento',\n",
    "                'benefits': ['Debug mais eficiente', 'Desenvolvimento mais r√°pido'],\n",
    "                'implementation': [\n",
    "                    'DevTools panel personalizado',\n",
    "                    'State inspector em tempo real',\n",
    "                    'Performance profiler integrado',\n",
    "                    'JSON diff visualizer'\n",
    "                ]\n",
    "            },\n",
    "            'hot_reloading': {\n",
    "                'description': 'Hot reloading avan√ßado para templates JSON',\n",
    "                'benefits': ['Desenvolvimento mais r√°pido', 'Estado preservado'],\n",
    "                'implementation': [\n",
    "                    'Watch mode para arquivos JSON',\n",
    "                    'Estado preservado durante reload',\n",
    "                    'Sync autom√°tico entre inst√¢ncias'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return optimizations\n",
    "\n",
    "def create_implementation_roadmap():\n",
    "    \"\"\"Cria roadmap de implementa√ß√£o das melhorias\"\"\"\n",
    "    \n",
    "    roadmap = {\n",
    "        'week_1': {\n",
    "            'title': 'Limpeza e Consolida√ß√£o',\n",
    "            'tasks': [\n",
    "                'Remover arquivos .backup duplicados',\n",
    "                'Aplicar Prettier em todos os componentes',\n",
    "                'Consolidar componentes similares',\n",
    "                'Padronizar imports e exports'\n",
    "            ],\n",
    "            'estimated_effort': '8 horas'\n",
    "        },\n",
    "        'week_2': {\n",
    "            'title': 'Refatora√ß√£o de Componentes Grandes',\n",
    "            'tasks': [\n",
    "                'Dividir EnhancedBlockRegistry em m√≥dulos menores',\n",
    "                'Refatorar componentes com >300 linhas',\n",
    "                'Extrair l√≥gica comum em hooks customizados',\n",
    "                'Implementar component composition pattern'\n",
    "            ],\n",
    "            'estimated_effort': '16 horas'\n",
    "        },\n",
    "        'week_3': {\n",
    "            'title': 'Otimiza√ß√£o de JSON e Performance',\n",
    "            'tasks': [\n",
    "                'Implementar cache de templates JSON',\n",
    "                'Adicionar lazy loading para componentes pesados',\n",
    "                'Otimizar renderiza√ß√£o com React.memo',\n",
    "                'Implementar virtual scrolling onde necess√°rio'\n",
    "            ],\n",
    "            'estimated_effort': '20 horas'\n",
    "        },\n",
    "        'week_4': {\n",
    "            'title': 'Melhorias de DX e Ferramentas',\n",
    "            'tasks': [\n",
    "                'Criar debugging tools personalizados',\n",
    "                'Implementar JSON schema validation',\n",
    "                'Adicionar hot reloading para templates',\n",
    "                'Documenta√ß√£o autom√°tica dos componentes'\n",
    "            ],\n",
    "            'estimated_effort': '12 horas'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return roadmap\n",
    "\n",
    "# Gerar otimiza√ß√µes e roadmap\n",
    "editor_optimizations = generate_editor_fixed_optimizations()\n",
    "implementation_roadmap = create_implementation_roadmap()\n",
    "\n",
    "print(\"üöÄ OTIMIZA√á√ïES PROPOSTAS PARA /editor-fixed\")\n",
    "print(\"\\nüèóÔ∏è  MELHORIAS DE ARQUITETURA:\")\n",
    "for category, details in editor_optimizations['architecture_improvements'].items():\n",
    "    print(f\"\\nüì¶ {category.upper()}:\")\n",
    "    print(f\"   {details['description']}\")\n",
    "    print(f\"   Benef√≠cios: {', '.join(details['benefits'])}\")\n",
    "\n",
    "print(\"\\nüìÖ ROADMAP DE IMPLEMENTA√á√ÉO:\")\n",
    "for week, details in implementation_roadmap.items():\n",
    "    print(f\"\\nüìù {week.upper()} - {details['title']}\")\n",
    "    print(f\"   Esfor√ßo estimado: {details['estimated_effort']}\")\n",
    "    for task in details['tasks']:\n",
    "        print(f\"   ‚Ä¢ {task}\")\n",
    "\n",
    "# Salvar plano de otimiza√ß√£o\n",
    "optimization_plan = f\"\"\"\n",
    "# üöÄ PLANO DE OTIMIZA√á√ÉO DO EDITOR-FIXED\n",
    "\n",
    "## üìä An√°lise de Complexidade Atual\n",
    "- Componentes analisados: {len(components_df)}\n",
    "- Componentes problem√°ticos: {len(components_df[components_df['issues'] != ''])}\n",
    "- Oportunidades de limpeza identificadas: {len(cleanup_report['duplicated_components']) + len(cleanup_report['oversized_components'])}\n",
    "\n",
    "## üéØ Objetivos das Otimiza√ß√µes\n",
    "1. **Reduzir complexidade** dos componentes mais problem√°ticos\n",
    "2. **Melhorar performance** com lazy loading e memoiza√ß√£o\n",
    "3. **Otimizar uso de JSON** com cache e valida√ß√£o\n",
    "4. **Melhorar DX** com ferramentas de debugging\n",
    "5. **Padronizar arquitetura** com padr√µes consistentes\n",
    "\n",
    "## üìÖ Cronograma de Implementa√ß√£o\n",
    "- **Semana 1**: Limpeza e consolida√ß√£o (8h)\n",
    "- **Semana 2**: Refatora√ß√£o de componentes grandes (16h)\n",
    "- **Semana 3**: Otimiza√ß√£o de performance (20h)\n",
    "- **Semana 4**: Melhorias de DX (12h)\n",
    "\n",
    "**Total estimado**: 56 horas de desenvolvimento\n",
    "\"\"\"\n",
    "\n",
    "plan_path = f\"{BASE_DIR}/EDITOR_OPTIMIZATION_PLAN.md\"\n",
    "with open(plan_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(optimization_plan)\n",
    "\n",
    "print(f\"\\nüíæ Plano de otimiza√ß√£o salvo em: {plan_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
